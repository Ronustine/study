[TOC]

系统搭建完毕，业务难以维护数据。需要使用相同的数据。

## 设计
- 每日业务量低点由分布式任务系统触发
- 筛出涉及到的商品哪些领域，划定好边界，整理出数据结构；
- 与基础数据系统开发逐个字段对接，看差异在哪里，怎么将有差异的数据，平滑转到系统中；
- 同步数据多，要速度不慢，而且可以看同步情况的功能；

## 同步情况
- 什么时候开启了同步，该同步是否完成 sync_task
- 同步涉及到哪些领域，每个领域同步进度怎么样 sync_task_detail
- 同步的异常有哪些 sync_task_detail_exception

由于要对同步情况要深入掌控细节，所以这些监控的代码对同步的流程也有很大的侵入性。

## 速度不慢
知道哪些领域有前后的逻辑关系，就是同步顺序反了会影响同步结果的，排好序，用一个线程来处理。得出一共可以开启几个线程处理。

批量插入。jpa批量插入，实际是一条条做的，要特殊处理。额外要考虑的如果批量处理如果出现了某条数据失败，那也需要转到单挑处理，失败的跳过，并做记录。
```java
    /**
     * 批量插入。注意：确保数据id不会重复，确认数据都属于insert操作
     * @param dataList 数据
     * @param <T> 基础bean
     * @return 数据
     */
    @Transactional(rollbackFor = Exception.class)
    public <T extends BaseIdBean> Iterable<T> batchInsert(List<T> dataList) {
        Iterator<T> iterator = dataList.iterator();
        int index = 0;
        while (iterator.hasNext()) {
            entityManager.persist(iterator.next());
            index ++;
            if (index % BATCH_SIZE == 0) {
                entityManager.flush();
                entityManager.clear();
            }
        }
        if (index % BATCH_SIZE != 0) {
            entityManager.flush();
            entityManager.clear();
        }
        return dataList;
    }
```

## 不影响用户
#### 切表
几个大表，直接删除会出现没数据的空档。而且还面临同步失败的风险。将数据同步到一个新表，完全同步完了，再做且表操作

## 问题
会出现同步中，服务重启的问题，进到发布系统，显示OOMKilled。借用arthas来获取堆的使用情况，找到相关代码，进行优化